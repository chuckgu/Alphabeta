# -*- coding: utf-8 -*-
from __future__ import absolute_import

import theano
import theano.tensor as T
from theano.sandbox.cuda import dnn
from theano.sandbox.cuda.dnn import GpuDnnConvDesc
from .Layers import Layer
from .Activations import relu,LeakyReLU,tanh,sigmoid,linear,mean,max,softmax,hard_sigmoid
from theano.tensor.signal.downsample import DownsampleFactorMax
import theano.tensor.nnet.conv3d2d
from theano.tensor.nnet import conv2d
from theano import shared, config, _asarray
from .Initializations import glorot_uniform,zero,alloc_zeros_matrix,glorot_normal,numpy_floatX,shared_zeros
from theano.tensor.signal import pool
floatX = config.floatX


class Convolution1D(Layer):
    def __init__(self, input_dim, nb_filter, filter_length,
                 activation='linear',
                 border_mode='valid', subsample_length=1):

        if border_mode not in {'valid', 'full', 'same'}:
            raise Exception('Invalid border mode for Convolution1D:', border_mode)

        self.nb_filter = nb_filter
        self.input_dim = input_dim
        self.filter_length = filter_length
        self.subsample_length = subsample_length
        self.activation = eval(activation)
        self.subsample = (1, subsample_length)
        self.border_mode = border_mode

        self.input = T.tensor3()
        self.x_mask=T.matrix()
        self.W_shape = (nb_filter, input_dim, filter_length, 1)
        self.W = glorot_uniform(self.W_shape)
        self.b = zero((nb_filter,))

        self.params = [self.W, self.b]

        self.L1=0
        self.L2_sqr=0

    def get_output(self, train=False):
        X = self.get_input(train)
        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)

        border_mode = self.border_mode
        if border_mode == 'same':
            border_mode = 'full'

        conv_out = T.nnet.conv.conv2d(X, self.W, border_mode=border_mode, subsample=self.subsample)
        if self.border_mode == 'same':
            shift_x = (self.filter_length - 1) // 2
            conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, :]

        output = conv_out + self.b.dimshuffle('x', 0, 'x', 'x')
        output = T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
        return output



class Convolution2D(Layer):
    def __init__(self, nb_filter, stack_size, nb_row, nb_col,
                 activation='linear',
                 border_mode='valid', subsample=(1, 1)):

        if border_mode not in {'valid', 'full', 'same'}:
            raise Exception('Invalid border mode for Convolution2D:', border_mode)


        self.activation = eval(activation)
        self.subsample = subsample
        self.border_mode = border_mode
        self.nb_filter = nb_filter
        self.stack_size = stack_size

        self.nb_row = nb_row
        self.nb_col = nb_col

        self.input = T.tensor4()
        self.x_mask=T.matrix()        
        self.W_shape = (nb_filter, stack_size, nb_row, nb_col)
        self.W = glorot_uniform(self.W_shape)
        self.b = zero((nb_filter,))

        self.params = [self.W, self.b]
        self.L1=0
        self.L2_sqr=0


    def get_output(self, train):
        X = self.get_input(train)
        border_mode = self.border_mode
        if dnn.dnn_available() and theano.config.device[:3] == 'gpu':
            if border_mode == 'same':
                assert(self.subsample == (1, 1))
                pad_x = (self.nb_row - self.subsample[0]) // 2
                pad_y = (self.nb_col - self.subsample[1]) // 2
                conv_out = dnn.dnn_conv(img=X,
                                        kerns=self.W,
                                        border_mode=(pad_x, pad_y))
            else:
                conv_out = dnn.dnn_conv(img=X,
                                        kerns=self.W,
                                        border_mode=border_mode,
                                        subsample=self.subsample)
        else:
            if border_mode == 'same':
                border_mode = 'full'

            conv_out = T.nnet.conv.conv2d(X, self.W,
                                          border_mode=border_mode,
                                          subsample=self.subsample)
            if self.border_mode == 'same':
                shift_x = (self.nb_row - 1) // 2
                shift_y = (self.nb_col - 1) // 2
                conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, shift_y:X.shape[3] + shift_y]

        return self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))

class Convolution3D(Layer):
    """ Convolutional layer, Filter Bank Layer """

    def __init__(self, nb_filter,nb_frame,stack_size,nb_row, 
        nb_col, activation='linear',border_mode='valid', subsample=(1, 1, 1),padding=(1,1,1)):

        """
        video_shape: (frames, height, width)
        kernel_shape: (frames, height, width)
        W_shape: (out, in, kern_frames, kern_height, kern_width)
        """
        
        dtensor5 = T.TensorType('float32', (False,)*5)
        self.input = dtensor5()
        self.x_mask=T.matrix()          
        
        self.activation = eval(activation)
        self.border_mode = border_mode
	self.subsample = subsample
	self.padding = padding

        self.nb_filter = nb_filter
        self.stack_size = stack_size
        self.nb_frame = nb_frame

        self.nb_row = nb_row
        self.nb_col = nb_col   
        
        self.W_shape = (nb_filter, nb_frame, stack_size, nb_row, nb_col)
        self.W = glorot_normal(self.W_shape)
        self.b = zero((nb_filter,))      
        

        self.params = [self.W, self.b]
        self.L1=0
        self.L2_sqr=0
        
        
    def get_output(self, train):
        X = self.get_input(train)   
	padding = self.padding

	if padding[0]<>0:
		input_shape = X.shape
		output_shape = (input_shape[0],
		                input_shape[1]+ 2 * self.padding[0], #depth
		                input_shape[2] ,
		                input_shape[3] + 2 * self.padding[1], #row
		                input_shape[4] + 2 * self.padding[2]) #col
		output = T.zeros(output_shape)
		indices = (slice(None),
			   slice(self.padding[0], input_shape[1] + self.padding[0]),
		           slice(None),
		           slice(self.padding[1], input_shape[3] + self.padding[1]),
		           slice(self.padding[2], input_shape[4] + self.padding[2]))
		X= T.set_subtensor(output[indices], X)
		del output

	
	out=theano.sandbox.cuda.dnn.dnn_conv3d(img=X.dimshuffle(0,2,1,3,4),
		                kerns=self.W.dimshuffle(0,2,1,3,4),
		                border_mode=self.border_mode,
		                subsample=self.subsample).dimshuffle([0,2,1,3,4])
        out += self.b.dimshuffle('x','x', 0 ,'x','x')
	'''
        border_mode_3d = (self.border_mode, self.border_mode, self.border_mode)
        out = T.nnet.conv3d2d.conv3d(
                signals=X, 
                filters=self.W, 
                border_mode=border_mode_3d)
        out += self.b.dimshuffle('x','x', 0 ,'x','x')
        '''

        
        return self.activation(out)



class MaxPooling1D(Layer):
    def __init__(self, pool_length=2, stride=None, ignore_border=True):
        self.pool_length = pool_length
        self.stride = stride
        if self.stride:
            self.st = (self.stride, 1)
        else:
            self.st = None

        self.input = T.tensor3()
        self.poolsize = (pool_length, 1)
        self.ignore_border = ignore_border
        
        self.params=[]
        self.x_mask=T.matrix() 
        self.L1=0
        self.L2_sqr=0
        
    def get_output(self, train):
        X = self.get_input(train)
        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)
        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)
        output = output.dimshuffle(0, 2, 1, 3)
        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))



class MaxPooling2D(Layer):
    def __init__(self, poolsize=(2, 2), stride=None, ignore_border=True):
        
        self.input = T.tensor4()
        self.poolsize = poolsize
        self.stride = stride
        self.ignore_border = ignore_border

        self.params=[]
        self.x_mask=T.matrix() 
        self.L1=0
        self.L2_sqr=0

    def get_output(self, train):
        X = self.get_input(train)
        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
        return output


class MaxPooling3D(Layer):
    """
    Takes as input a N-D tensor, where N >= 3. It downscales the input video by
    the specified factor, by keeping only the maximum value of non-overlapping
    patches of size (ds[0],ds[1],ds[2]) (time, height, width)

    :type input: N-D theano tensor of input images.
    :param input: input images. Max pooling will be done over the 3 last dimensions.
    :type ds: tuple of length 3
    :param ds: factor by which to downscale. (2,2,2) will halve the video in each dimension.
    :param ignore_border: boolean value. When True, (5,5,5) input with ds=(2,2,2) will generate a
      (2,2,2) output. (3,3,3) otherwise.
    """
    def __init__(self, poolsize=(2, 2, 2), stride=(2, 2, 2), ignore_border=True):

        dtensor5 = T.TensorType('float32', (False,)*5)
        self.input = dtensor5()
        self.poolsize = poolsize
        self.stride = stride
        self.ignore_border = ignore_border

        self.params=[]
        self.x_mask=T.matrix() 
        self.L1=0
        self.L2_sqr=0        


    def get_output(self, train):       
        X = self.get_input(train)
	X=X.dimshuffle(0,2,3,4,1)
	pool_mode = 'max'
	pool_size = self.poolsize
	strides = self.stride
	ignore_border = self.ignore_border
	padding = (0, 0)

        if X.ndim < 3:
            raise NotImplementedError('max_pool_3d requires a dimension >= 3')

	if pool_mode == 'max':
	    # pooling over conv_dim2, conv_dim1 (last two channels)
	    output = pool.pool_2d(input=X.dimshuffle(0, 1, 4, 3, 2),
	                      ds=(pool_size[1], pool_size[0]),
	                      st=(strides[1], strides[0]),
	                      ignore_border=ignore_border,
	                      padding=padding,
	                      mode='max')

	    # pooling over conv_dim3
	    pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
	                        ds=(1, pool_size[2]),
	                        st=(1, strides[2]),
	                        ignore_border=ignore_border,
	                        padding=padding,
	                        mode='max')

	elif pool_mode == 'avg':
	    # pooling over conv_dim2, conv_dim1 (last two channels)
	    output = pool.pool_2d(input=X.dimshuffle(0, 1, 4, 3, 2),
		                      ds=(pool_size[1], pool_size[0]),
		                      st=(strides[1], strides[0]),
		                      ignore_border=ignore_border,
		                      padding=padding,
		                      mode='average_exc_pad')

	    # pooling over conv_dim3
	    pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
		                        ds=(1, pool_size[2]),
		                        st=(1, strides[2]),
		                        ignore_border=ignore_border,
		                        padding=padding,
		                        mode='average_exc_pad')
	else:
	    raise Exception('Invalid pooling mode: ' + str(pool_mode))


	return pool_out.dimshuffle(0,4,1,2,3)


    	'''
        # extract nr dimensions
        vid_dim = X.ndim
        # max pool in two different steps, so we can use the 2d implementation of 
        # downsamplefactormax. First maxpool frames as usual. 
        # Then maxpool the time dimension. Shift the time dimension to the third 
        # position, so rows and cols are in the back
    
        # extract dimensions
        frame_shape = X.shape[-2:]
        
        # count the number of "leading" dimensions, store as dmatrix
        batch_size = T.prod(X.shape[:-2])
        batch_size = T.shape_padright(batch_size,1)
        
        # store as 4D tensor with shape: (batch_size,1,height,width)
        new_shape = T.cast(T.join(0, batch_size,
                                            T.as_tensor([1,]), 
                                            frame_shape), 'int32')
        input_4D = T.reshape(X, new_shape, ndim=4)
    
        # downsample mini-batch of videos in rows and cols
        op = DownsampleFactorMax((self.poolsize[1],self.poolsize[2]), self.ignore_border,(self.stride[1],self.stride[2]))
        output = op(input_4D)
        # restore to original shape
        outshape = T.join(0, X.shape[:-2], output.shape[-2:])
        out = T.reshape(output, outshape, ndim=X.ndim)
    
        # now maxpool time
    
        # output (time, rows, cols), reshape so that time is in the back
        shufl = (list(range(vid_dim-3)) + [vid_dim-2]+[vid_dim-1]+[vid_dim-3])
        input_time = out.dimshuffle(shufl)
        # reset dimensions
        vid_shape = input_time.shape[-2:]
        
        # count the number of "leading" dimensions, store as dmatrix
        batch_size = T.prod(input_time.shape[:-2])
        batch_size = T.shape_padright(batch_size,1)
        
        # store as 4D tensor with shape: (batch_size,1,width,time)
        new_shape = T.cast(T.join(0, batch_size,
                                            T.as_tensor([1,]), 
                                            vid_shape), 'int32')
        input_4D_time = T.reshape(input_time, new_shape, ndim=4)
        # downsample mini-batch of videos in time
        op = DownsampleFactorMax((1,self.poolsize[0]), self.ignore_border,(1,self.stride[0]))
        outtime = op(input_4D_time)
        # output 
        # restore to original shape (xxx, rows, cols, time)
        outshape = T.join(0, input_time.shape[:-2], outtime.shape[-2:])
        shufl = (list(range(vid_dim-3)) + [vid_dim-1]+[vid_dim-3]+[vid_dim-2])
        return T.reshape(outtime, outshape, ndim=X.ndim).dimshuffle(shufl)
	'''



class UpSample1D(Layer):
    def __init__(self, length=2):
        
        self.length = length
        self.input = T.tensor3()

    def get_output(self, train):
        X = self.get_input(train)
        output = theano.tensor.extra_ops.repeat(X, self.length, axis=1)
        return output



class UpSample2D(Layer):
    def __init__(self, size=(2, 2)):
        
        self.input = T.tensor4()
        self.size = size

    def get_output(self, train):
        X = self.get_input(train)
        Y = theano.tensor.extra_ops.repeat(X, self.size[0], axis=2)
        output = theano.tensor.extra_ops.repeat(Y, self.size[1], axis=3)
        return output


class ZeroPadding2D(Layer):
    def __init__(self, pad=(1, 1)):
        
        self.pad = pad
        self.input = T.tensor4()

    def get_output(self, train):
        X = self.get_input(train)
        pad = self.pad
        in_shape = X.shape
        out_shape = (in_shape[0], in_shape[1], in_shape[2] + 2 * pad[0], in_shape[3] + 2 * pad[1])
        out = T.zeros(out_shape)
        indices = (slice(None), slice(None), slice(pad[0], in_shape[2] + pad[0]), slice(pad[1], in_shape[3] + pad[1]))
        return T.set_subtensor(out[indices], X)





